{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data and The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherwin\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (1,2,4,5,6,7,8,9,10,11,12,13,14,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import decomposition\n",
    "\n",
    "\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "\n",
    "df = pd.read_csv(\"HumidityDataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping all the libraires and selecting only rows that start after the 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"longitude\",\"latitude\", \"WaveHeight\", \"WavePeriod\", \"MeanWaveDirection\", \"Hmax\",\"QC_Flag\"],inplace = True, axis = 1)\n",
    "df = df.iloc[331371:]\n",
    "buoy_ident = { 'M2':1 , 'M3': 2, 'M4':3, 'M5': 4, 'M6': 5}\n",
    "# df.station_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the values of rows that have buoys ident as M2 to M6\n",
    "df = df.loc[df.station_id.isin(buoy_ident.keys()) ]\n",
    "df = df.drop([\"time\"], axis = 1)\n",
    "# df.station_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({ 'station_id': buoy_ident})\n",
    "df = df.dropna(axis = 1, how='all')\n",
    "df.reset_index(inplace = True)\n",
    "df.dropna(inplace = True, how = 'all')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>AtmosphericPressure</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>Gust</th>\n",
       "      <th>AirTemperature</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>SeaTemperature</th>\n",
       "      <th>RelativeHumidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>10.3</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1011.2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1009.4</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>5.7</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>10.4</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1009</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id AtmosphericPressure WindDirection WindSpeed Gust AirTemperature  \\\n",
       "0           1              1007.2            50        17   25            5.5   \n",
       "1           5              1015.8            20        18   33              7   \n",
       "3           3              1011.2            10        12   20            4.7   \n",
       "4           2              1009.4            30        17   25            5.7   \n",
       "5           2                1009            20        18   25            5.3   \n",
       "\n",
       "  DewPoint SeaTemperature RelativeHumidity  \n",
       "0     -1.1           10.3               62  \n",
       "1      0.9           11.4               65  \n",
       "3      1.1           10.2               78  \n",
       "4     -1.2           10.4               61  \n",
       "5     -0.3           10.4               67  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.drop('index', axis = 1, inplace = True)\n",
    "df.head()\n",
    "\n",
    "# df.reset_index(inplace= True)\n",
    "# df.isna()\n",
    "# drop('index',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68427, 8)\n",
      "[[ 0.24974425 -0.00056802 -0.04797773 ...  0.14099914  0.19979288\n",
      "   0.12685025]\n",
      " [ 0.24974425  0.04002238  0.3964667  ...  0.17509004  0.02975238\n",
      "   0.21613596]\n",
      " [-0.50025576  0.04002238  0.4242445  ... -0.02377359 -0.01073345\n",
      "  -0.08743546]\n",
      " ...\n",
      " [ 0.24974425 -0.01606617 -0.02019995 ...  0.15804459  0.13096696\n",
      "   0.13577883]\n",
      " [-0.50025576  0.06363862  0.3131334  ...  0.13531731  0.14716129\n",
      "   0.15363596]\n",
      " [ 0.24974425  0.04076039 -0.04797773 ...  0.08418095  0.10667546\n",
      "   0.07327882]]\n",
      "(68427,)\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(df.iloc[:,:-1].values,df.iloc[:,-1].values, test_size=0.2)\n",
    "print(X_train1.shape)\n",
    "\n",
    "class CustomScaler():\n",
    "    \n",
    "        def __init__(self, X_Scale, y_Scale ) :\n",
    "        \n",
    "            self.X_Scale =   X_Scale \n",
    "            self.y_Scale =   y_Scale\n",
    "            \n",
    "            self.x_num =     [np.mean(self.X_Scale[:,i]) for i in range(self.X_Scale.shape[1])]\n",
    "            self.x_maxs =    [np.max(self.X_Scale[:,i]) for i in range(self.X_Scale.shape[1])]\n",
    "            self.x_mins =    [np.min(self.X_Scale[:,i]) for i in range(self.X_Scale.shape[1])]\n",
    "            \n",
    "            self.y_num =     np.mean(self.y_Scale)\n",
    "            self.y_max_min = np.max(self.y_Scale) - np.min(self.y_Scale)\n",
    "\n",
    "        def scaleX(self, x_value):\n",
    "            x = x_value.copy()\n",
    "            for i in range(x.shape[1]):\n",
    "                \n",
    "                x[:,i]= (x[:,i] - self.x_num[i])/(self.x_maxs[i]-self.x_mins[i])\n",
    "            return x\n",
    "\n",
    "        def inverseScaleX(self, x_value):\n",
    "            x = x_value.copy()\n",
    "            \n",
    "            for i in range(x.shape[1]):\n",
    "                x[:,i]= (x[:,i] * (self.x_maxs[i]-self.x_mins[i])) + self.x_num[i]\n",
    "            return x\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        def scaleY(self, y_value):\n",
    "            y = y_value.copy()\n",
    "            ys = (y - self.y_num)/(self.y_max_min)\n",
    "            return ys\n",
    "\n",
    "        def inverseScaleY(self, y_value):\n",
    "            y = y_value.copy()\n",
    "            ys = (y * self.y_max_min) + self.y_num\n",
    "            return ys\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "custom_scaler = CustomScaler(X_train1,y_train1)\n",
    "    \n",
    "X_train = custom_scaler.scaleX(X_train1.copy())\n",
    "y_train = custom_scaler.scaleY(y_train1.copy())\n",
    "\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "transform = None\n",
    "\n",
    "\n",
    "print(X_train[-70000: -1])\n",
    "\n",
    "print(y_train1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('station_id', 0.00011547026245210912)\n",
      "('AtmosphericPressure', 0.00016945066588258196)\n",
      "('WindDirection', 0.000124555107387325)\n",
      "('WindSpeed', 0.00010133218437444298)\n",
      "('Gust', 0.00010008541005791994)\n",
      "('AirTemperature', 0.20218923334652647)\n",
      "('DewPoint', 0.7133706926345369)\n",
      "('SeaTemperature', 0.0838291803887822)\n",
      "AirTemperature\n",
      "DewPoint\n"
     ]
    }
   ],
   "source": [
    "x_columns = df.columns[0:-1]\n",
    "\n",
    "for feature in zip(x_columns, clf.feature_importances_):\n",
    "    print(feature)\n",
    "    \n",
    "sfm = SelectFromModel(clf, threshold=0.15)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)\n",
    "\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(x_columns[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station_id', 'AtmosphericPressure', 'WindDirection', 'WindSpeed',\n",
       "       'Gust', 'AirTemperature', 'DewPoint', 'SeaTemperature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():    \n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(10, activation = \"relu\",input_dim = X_train.shape[1], name = \"layer1\"))\n",
    "    model.add(Dense(20, activation = \"relu\", name = \"layer2\"))\n",
    "    model.add(Dense(20, activation = \"relu\", name = \"layer5\"))\n",
    "    model.add(Dense(20, activation = \"relu\", name = \"layer6\"))\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer='normal', name = \"layer7\"))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer='SGD')\n",
    "    return model\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "estimator = KerasRegressor(build_fn=model1, epochs=1000, batch_size=4096, verbose=1,callbacks=[es])\n",
    "history=estimator.fit(np.asarray(X_train).astype('float32'),np.asarray(y_train).astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "#history = model.fit(x_pca, df.iloc[:, -1], batch_size=batch_size, epochs=20, validation_split=0.1)\n",
    "# estimator = KerasRegressor(build_fn=model, epochs=100, batch_size=batch_size, verbose=0)\n",
    "# history = model.fit(np.asarray(x).astype('float32'),np.asarray(y).astype('float32') , epochs=150, batch_size=50,  verbose=1, validation_split=0.3)\n",
    "# kfold = KFold(n_splits=5)\n",
    "# results = cross_val_score(estimator,np.asarray(x).astype('float32'), np.asarray(y).astype('float32'), cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "if transform:\n",
    "    y_pred = estimator.predict(transformer.transform(custom_scaler.scaleX(np.asarray(X_test1).astype('float32'))))\n",
    "else :\n",
    "    y_pred = estimator.predict((custom_scaler.scaleX(np.asarray(X_test1).astype('float32'))))\n",
    "\n",
    "# y_pred = max_min*y_pred + y_min\n",
    "print(mean_squared_error(custom_scaler.inverseScaleY(y_pred), y_test1))\n",
    "y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.column_stack((y_test1,custom_scaler.inverseScaleY(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTest = scaler.inverse_transform(np.column_stack((X_test, y_pred)))\n",
    "ogTest = scaler.inverse_transform(np.column_stack((X_test, y_test)))\n",
    "np.column_stack((predTest[:, -1], ogTest[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
